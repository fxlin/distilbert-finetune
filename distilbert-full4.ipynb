{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9558a1eb-d710-4251-bfbd-a84c6bd5b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "#!pip install datasets transformers[sentencepiece]\n",
    "#!pip install ipywidgets\n",
    "#!pip install torchsummary \n",
    "#!pip install accelerate \n",
    "#!pip3 install matplotlib\n",
    "\n",
    "# cf: Huggingface\n",
    "# https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb#scrollTo=nZ09SFwfjXNO\n",
    "# Google\n",
    "# https://colab.research.google.com/github/501Good/tartu-nlp-2020/blob/master/labs/lab6/Lab6_TransformersClassification.ipynb#scrollTo=yfUd-Wr3t7rO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4b6c1-cdff-4eaf-85ef-2d877c1aad24",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812ab5e7-0a11-4244-8d32-e7351114ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "# xzl\n",
    "config_batch_size = 8\n",
    "config_per_sample = True   # otherwise per minibatch\n",
    "config_n_window = config_batch_size * 16 # mov window avg for cal loss threshold, in num of samples \n",
    "config_layer_mask = [1,1,1,1,1,1]   # per layer. 1=train, 0=freeze\n",
    "# config_layer_mask = [0,0,0,0,0,1]   # per layer. 1=train, 0=freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72bb884-d550-4348-9ffb-96a9139905fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# # load pre-trained\n",
    "# #  ... many weights are not init'd... random??\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068c3483-8562-4e7e-8134-96c5779a5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dump model \n",
    "#\n",
    "# cf: \n",
    "# https://stackoverflow.com/questions/68577198/pytorch-summary-fails-with-huggingface-model\n",
    "# https://stackoverflow.com/questions/68585678/pytorch-summary-fails-with-huggingface-model-ii-expected-all-tensors-to-be-on-t\n",
    "# torch info doc: \n",
    "# https://github.com/TylerYep/torchinfo\n",
    "# ... works, but not very helpful\n",
    "# summary(model,input_size=(8,512), dtypes=['torch.IntTensor'], device='cpu',verbose=1) \n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "#    if param.requires_grad:\n",
    "#        print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b621db-e7c9-43a6-b927-3b19b11bdfab",
   "metadata": {},
   "source": [
    "## (save model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd25d66e-80eb-4d60-94ac-0c44af16e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################\n",
    "# # save model ...\n",
    "# ########################\n",
    "# # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "# output_dir = './model_save/'\n",
    "\n",
    "# # Create output directory if needed\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# # They can then be reloaded using `from_pretrained()`\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "# model_to_save.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# # Good practice: save your training arguments together with the trained model\n",
    "# # torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1ae98-ffdb-4429-9eb5-e20516aa9a0f",
   "metadata": {},
   "source": [
    "## (load a saved model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d56d7d7-d008-4d40-9e45-59ee3a9a3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "\n",
    "#output_dir = './distilbert/model_save/'  # VScode needs this relative path??\n",
    "# output_dir = './model_save/'  # VScode needs this relative path??\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "# metric = load_metric(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75625d1-da35-43c7-9379-201ce659497e",
   "metadata": {},
   "source": [
    "## (model printing, layerwise freezing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4209ce22-1a30-4d96-b8f2-e002ae232a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DistilBERT model has 104 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "distilbert.embeddings.word_embeddings.weight            (30522, 768)\n",
      "distilbert.embeddings.position_embeddings.weight          (512, 768)\n",
      "distilbert.embeddings.LayerNorm.weight                        (768,)\n",
      "distilbert.embeddings.LayerNorm.bias                          (768,)\n",
      "distilbert.transformer.layer.0.attention.q_lin.weight     (768, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "distilbert.transformer.layer.0.attention.q_lin.bias           (768,)\n",
      "distilbert.transformer.layer.0.attention.k_lin.weight     (768, 768)\n",
      "distilbert.transformer.layer.0.attention.k_lin.bias           (768,)\n",
      "distilbert.transformer.layer.0.attention.v_lin.weight     (768, 768)\n",
      "distilbert.transformer.layer.0.attention.v_lin.bias           (768,)\n",
      "distilbert.transformer.layer.0.attention.out_lin.weight   (768, 768)\n",
      "distilbert.transformer.layer.0.attention.out_lin.bias         (768,)\n",
      "distilbert.transformer.layer.0.sa_layer_norm.weight           (768,)\n",
      "distilbert.transformer.layer.0.sa_layer_norm.bias             (768,)\n",
      "distilbert.transformer.layer.0.ffn.lin1.weight           (3072, 768)\n",
      "distilbert.transformer.layer.0.ffn.lin1.bias                 (3072,)\n",
      "distilbert.transformer.layer.0.ffn.lin2.weight           (768, 3072)\n",
      "distilbert.transformer.layer.0.ffn.lin2.bias                  (768,)\n",
      "distilbert.transformer.layer.0.output_layer_norm.weight       (768,)\n",
      "distilbert.transformer.layer.0.output_layer_norm.bias         (768,)\n",
      "distilbert.transformer.layer.1.attention.q_lin.weight     (768, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "pre_classifier.weight                                     (768, 768)\n",
      "pre_classifier.bias                                           (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The DistilBERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "\n",
    "for layer in range(0,6):\n",
    "    # 0th layer: params [5..21]. each layer 16 params, 6 layers\n",
    "    if layer == 0: \n",
    "        print('\\n==== First Transformer ====\\n')                \n",
    "    for p in params[5+16*layer : 21+16*layer]:\n",
    "        if layer == 0: \n",
    "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "        if config_layer_mask[layer] == 0: \n",
    "            p[1].requires_grad = False   # xzl ... freeze\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "        \n",
    "# freeze transformer layers (TODO: freeze other layers??)\n",
    "# for param in model.distilbert.parameters():\n",
    "#     param.requires_grad = False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2ba079-6c19-4595-974a-fc8c171e6c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xzl: this???\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "def to_bin_class(ex):\n",
    "\tex['label'] = round(ex['label'])\n",
    "\treturn ex\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "\treturn tokenizer(ex['sentence'], padding='max_length', truncation=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\tlogits, labels = eval_pred\n",
    "\tpreds = np.argmax(logits, axis=-1)\n",
    "\treturn metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153e338-8a4d-4144-94d4-51952d74b51d",
   "metadata": {},
   "source": [
    "# load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69abea0a-1876-4bb1-83e0-78fd7e36b0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sst (/u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf0f8f47c504f01a1ccd4b560fa0f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-175e01bd44ae6e77.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-bcfe3eb7a84204f3.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-d17996794240dda4.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-a4488ee52a49920a.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1c1de7b235a26b22.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-e13f66f58e1dc770.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-4fde5a6aea4f6c63.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-8907ad2a7135934b.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-8432e9f63b9a4002.arrow\n"
     ]
    }
   ],
   "source": [
    "sst = load_dataset('sst', 'default')\n",
    "#sst = load_dataset('glue', 'sst2')\n",
    "sst = sst.remove_columns(['tokens', 'tree'])\n",
    "sst = sst.map(to_bin_class)\n",
    "sst = sst.cast_column('label', ClassLabel(num_classes=2))\n",
    "\n",
    "sst_tokenized = sst.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98b7fda-569a-4e06-991a-52aa73dceb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "sst_tokenized = sst_tokenized.remove_columns(['sentence'])\n",
    "\n",
    "trn_set = sst_tokenized['train']\n",
    "num_trn = trn_set.num_rows\n",
    "trn_set_10 = torch.utils.data.Subset(trn_set, list(range(0,int(num_trn/10))))\n",
    "trn_set_50 = torch.utils.data.Subset(trn_set, list(range(0,int(num_trn/2))))\n",
    "tst_set = sst_tokenized['test']\n",
    "val_set = sst_tokenized['validation']\n",
    "\n",
    "print(val_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4ecf5f-a1e0-4f51-8083-ab2eb37d68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faa7193596343b7923d38fa0545212f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a7fd750de98eccdc.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cb82f2b3146ed290.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc351fc2d3a49113.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee0643d23beb47af.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-44f2a071873c044a.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-83c969729e91a5a4.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d74374a665bb1853.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8835c5b7126a568b.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5f8bc1f13660d4f5.arrow\n"
     ]
    }
   ],
   "source": [
    "sst2 = load_dataset('glue', 'sst2')\n",
    "sst2 = sst2.map(to_bin_class)\n",
    "sst2 = sst2.cast_column('label', ClassLabel(num_classes=2))\n",
    "\n",
    "sst2_tokenized = sst2.map(tokenize_fn, batched=True)\n",
    "\n",
    "sst2_tokenized = sst2_tokenized.remove_columns(['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc23bd52-8344-480b-b8d5-98c7b8baae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "trn_set = sst_tokenized['train']\n",
    "num_trn = trn_set.num_rows\n",
    "tst_set = sst_tokenized['test']\n",
    "val_set = sst_tokenized['validation']\n",
    "\n",
    "print(val_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51370166-f49a-4af6-a17d-5e5f34e8017e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data loader, split into train/eval sets\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "   trn_set, shuffle=True, batch_size=config_batch_size, collate_fn=data_collator\n",
    "   # trn_set_100, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator\n",
    "    # trn_set_500, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator    \n",
    "    # trn_set_1000, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator    \n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    val_set, batch_size=config_batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db319f2-fadd-4e4f-afec-09f04a431300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 512]),\n",
       " 'attention_mask': torch.Size([8, 512]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a batch is a dict. k is col name, e.g. 'input_ids'. v is a 2D tensor (8x512 in our case)\n",
    "\n",
    "# sanity check data ...\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}    \n",
    "#batch.items()\n",
    "#print(batch['input_ids'])\n",
    "#print(\"train #batches=\",len(train_dataloader))\n",
    "#print(\"val #batches=\",len(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9902d696-e69b-4d32-94b7-8b6339f35a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6944, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n",
      "SequenceClassifierOutput(loss=tensor(0.6944, grad_fn=<NllLossBackward0>), logits=tensor([[0.0852, 0.0806],\n",
      "        [0.0861, 0.0891],\n",
      "        [0.0664, 0.0561],\n",
      "        [0.0608, 0.0923],\n",
      "        [0.0681, 0.1065],\n",
      "        [0.1189, 0.0548],\n",
      "        [0.0176, 0.0261],\n",
      "        [0.1152, 0.0556]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "tensor([[0.5011, 0.4989],\n",
      "        [0.4993, 0.5007],\n",
      "        [0.5026, 0.4974],\n",
      "        [0.4921, 0.5079],\n",
      "        [0.4904, 0.5096],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.4979, 0.5021],\n",
      "        [0.5149, 0.4851]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run one batch\n",
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)\n",
    "print(outputs)\n",
    "# probablity\n",
    "print(torch.nn.functional.softmax((outputs.logits),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58a1b57-066d-426b-9ab8-a9af38583e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor t in optimizer.param_groups[0]['params']:\\n    print(t.shape)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... prep optim lr scheduler etc  ... \n",
    "#from transformers import AdamW    # deprecated\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# optimizer.param_groups[0]['params']\n",
    "# print(len(optimizer.param_groups[0]['params']))\n",
    "\n",
    "'''\n",
    "for t in optimizer.param_groups[0]['params']:\n",
    "    print(t.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11fc988-40fa-4023-935f-15dffa473546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 1    # xzl. default:3\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "# print(model)  # can be useful\n",
    "\n",
    "#summary(model,input_size=(8,512)) # ... type errors??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426d65d2-e4c4-43dc-b93b-6b8ecbe182e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "# excluded_batches = []\n",
    "# bottom 50%\n",
    "# excluded_batches = [0,2,6,5,1,4,3,8,7,10,9,11,581,870,525,785,12,13,827,811,422,973,1021,14,320,967,140,122,583,624,935,542,936,924,618,777,22,591,888,331,32,593,852,813,297,825,15,156,687,30,75,1029,643,538,774,19,530,234,287,25,724,943,316,93,978,427,384,611,464,750,900,361,432,519,208,760,553,625,336,982,111,179,312,104,471,26,845,17,68,855,695,139,293,177,552,144,897,548,706,1036,856,379,482,902,627,500,817,814,415,601,18,726,557,20,860,100,229,249,332,103,355,948,939,1049,824,579,822,895,450,1027,896,467,80,456,266,202,736,887,260,185,1062,974,1028,1060,781,933,165,309,255,480,240,700,108,232,461,993,184,381,458,296,1022,88,1001,395,323,91,1000,69,991,330,359,965,727,63,851,347,253,995,916,697,917,584,152,690,616,957,463,1006,843,76,466,378,135,663,286,50,770,410,539,201,92,879,506,647,70,236,245,998,181,248,404,741,29,954,209,306,246,119,268,949,133,1026,1056,418,449,196,682,221,918,863,806,1019,992,65,125,24,821,66,692,56,739,243,617,554,1015,397,550,416,79,748,95,406,409,149,1017,89,281,174,512,367,469,445,696,251,648,753,944,121,694,702,54,592,575,675,926,990,264,284,205,150,123,963,167,180,898,613,755,794,16,118,448,36,884,176,681,674,454,913,72,844,84,128,776,485,130,861,452,385,164,772,529,834,319,838,789,227,883,1011,468,988,479,672,274,803,407,1058,722,265,77,701,254,258,388,346,622,31,460,572,1033,413,698,484,38,612,1013,805,473,890,962,751,573,1047,637,462,389,956,113,951,927,375,937,282,82,197,244,971,168,98,33,964,368,382,451,1010,64,55,163,365,1031,537,1039,829,328,1025,603,833,641,324,711,880,486,459,1065,629,650,470,373,420,457,653,220,472,147,666,83,533,223,496,656,160,439,1023,947,1018,742,294,713,508,878,858,301,910,735,975,871,498,795,175,731,200,109,350,693,628,1024,28,157,342,730,551,646,1012,351,516,819,279,638,433,901,532,831,792,396,689,455,985,21,931,363,968,972,57,137,941,411,453,699,154,477,414,986,345,81,492,143,73,679,474,1009,206,425,952,145,1067,210,124,981,364,830,652,290,169,872,676,358,798,1005,899,773,906,636,678,325,869,172,400,252,846,441,745,570,1037,510,131,1064,737,606,644,231,360,1061,215,534,170,178,857,1032,408,994,812,1007,651,784,356,]\n",
    "# bottom 75%\n",
    "# excluded_batches = [16,4,12,18,6,7,22,13,9,19,11,5,2,14,17,20,25,21,15,3,10,27,24,8,1,29,23,30,28,26,0,32,31,670,34,630,943,168,979,225,33,92,940,599,595,989,456,1064,930,131,106,432,35,695,916,726,592,1014,453,729,565,622,117,806,637,258,1061,36,672,783,846,750,908,794,490,312,378,484,1047,814,144,980,854,947,145,404,318,566,781,498,506,1013,971,874,159,613,83,692,681,689,118,699,259,289,183,77,1002,128,60,415,417,160,1018,151,130,910,583,1043,679,684,139,1017,43,1010,757,1006,765,52,157,995,928,277,460,402,718,913,500,147,122,898,996,61,970,288,135,133,124,962,522,994,655,40,441,37,81,576,349,245,138,134,467,1031,38,50,529,774,961,333,914,45,915,963,905,74,152,964,430,362,330,201,331,395,337,1001,79,984,525,357,303,323,901,374,297,80,585,638,226,548,344,615,266,835,591,517,62,938,355,360,519,274,140,602,890,184,353,804,667,559,717,701,586,683,429,46,265,189,568,69,324,364,923,1036,499,472,937,827,521,82,85,343,687,282,438,792,745,222,72,112,580,171,464,927,291,121,120,268,569,75,925,627,501,748,546,55,785,1027,166,639,992,893,494,551,71,238,485,713,818,39,444,839,41,359,326,363,563,70,1011,953,823,990,673,325,859,78,746,843,656,960,669,577,1042,316,101,919,273,252,126,396,153,346,508,883,663,177,575,668,845,798,696,856,84,716,286,997,132,405,371,777,561,345,180,398,653,311,877,579,719,214,423,918,67,205,53,113,116,832,369,208,191,966,791,452,768,356,632,676,751,269,448,424,541,123,816,1055,550,873,865,380,372,657,926,543,704,86,851,1040,457,641,974,564,137,281,942,694,707,150,219,270,256,413,658,470,891,427,1065,944,648,742,428,262,852,284,903,597,520,414,193,198,838,691,301,626,549,959,710,909,253,954,310,581,574,382,786,491,711,473,685,836,931,620,154,584,329,878,65,876,848,59,475,822,706,42,820,682,93,828,801,367,322,451,882,635,279,594,532,582,573,217,264,216,867,866,129,978,1041,693,304,870,934,476,437,879,283,255,612,1054,624,233,513,739,425,643,320,1046,795,531,54,88,110,342,347,759,702,540,784,552,468,678,336,148,948,474,1039,246,642,976,399,1050,528,410,351,335,842,275,250,847,922,523,1032,1025,956,115,659,1058,334,76,190,267,108,778,315,932,125,486,888,352,516,988,633,397,578,478,221,1052,800,524,629,570,744,287,588,951,872,408,730,477,981,993,158,892,858,375,810,299,769,447,459,697,767,298,728,731,849,857,841,601,686,544,790,675,203,1004,1016,366,542,328,714,646,920,703,507,143,605,621,212,1020,412,753,977,911,936,808,454,889,338,982,518,896,560,272,443,276,509,57,824,895,593,502,1044,493,327,952,1051,875,625,688,645,63,793,787,73,619,1021,611,881,211,512,321,674,392,618,897,871,278,271,945,819,975,377,571,407,481,1045,662,724,169,426,968,339,572,194,370,439,230,514,261,463,983,383,368,782,607,972,213,306,254,234,690,812,533,1059,434,955,887,526,244,156,406,985,912,465,48,864,141,341,361,698,302,290,803,249,965,598,294,207,829,805,869,700,431,422,680,204,305,884,178,44,241,416,1009,243,192,537,248,202,98,837,538,365,215,536,181,1037,285,752,487,868,661,715,1003,175,182,530,164,247,419,185,949,223,172,732,562,723,503,917,1057,142,236,280,296,587,721,821,505,545,608,1030,780,735,87,206,969,497,558,567,504,96,308,257,89,99,510,1053,97,95,834,797,736,483,492,855,939,830,802,924,666,471,705,167,603,853,]\n",
    "\n",
    "# -- include all --- #\n",
    "included_batches = list(range(0, len(train_dataloader)))\n",
    "\n",
    "# loss, top 10 \n",
    "# included_batches = [0,12,606,28,908,14,629,647,229,961,683,156,921,84,868,74,1031,801,7,296,948,219,525,343,624,29,466,56,203,55,436,260,643,266,11,153,112,636,308,664,781,927,106,1024,465,197,726,19,278,90,173,50,533,53,42,925,357,77,902,612,281,318,799,43,911,263,422,111,259,198,71,225,482,832,723,782,790,588,476,689,904,383,479,631,139,556,771,1061,253,51,719,728,941,392,344,395,783,456,538,655,973,968,282,83,965,756,]\n",
    "# bottom 10\n",
    "# included_batches = [593,1029,414,1009,574,529,417,678,966,398,843,616,594,869,597,651,998,1059,1051,338,402,899,875,931,883,129,1034,166,496,422,1013,695,781,412,485,1044,440,708,240,792,773,935,785,816,905,689,624,321,364,249,383,775,863,854,937,757,667,587,558,945,310,745,445,435,599,648,968,735,600,965,1060,893,924,1043,231,81,888,592,608,1019,404,256,575,856,679,956,581,641,343,583,643,507,582,699,761,842,436,397,1052,1066,248,330,782,783,395,391,]\n",
    "\n",
    "skip_counter = 0  # how many sample skipped\n",
    "\n",
    "#loss_history = []\n",
    "loss_history = np.array([], dtype=np.float32)\n",
    "loss_history_eff = np.array([], dtype=np.float32)   # effective. actual loss in training\n",
    "\n",
    "# loss_threshold = 0 # 0.4 # 0.4   # higher -> skip more; lower -> skip less\n",
    "loss_threshold = 0\n",
    "loss_threshold_history = []\n",
    "\n",
    "#for picking examples based on rankings in a minibatch. only backprop these examples\n",
    "keep_frac = 0.5   \n",
    "\n",
    "# dict()\n",
    "# list of 1D tensors...\n",
    "staged_batch = {'input_ids':[], 'attention_mask':[], 'labels':[]} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51710765-f531-414d-a0ba-6378c4f25bc5",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "165d98de-5345-4cc6-81c1-19471a49d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a5b938ef874e0db797dd7fa88fc5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 4m 0s\n",
      "  skipped 4889 samples, 57.22% loss_threshold 0.66477734\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0m 14s\n",
      "Accuracy:  {'accuracy': 0.8446866485013624}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Effective Loss histo')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# train/validation per epoch\n",
    "loss_values = []\n",
    "\n",
    "loss_threshold_history.append((0, loss_threshold))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, num_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    skip_counter = 0\n",
    "    \n",
    "    progress_bar = tqdm(range(len(train_dataloader) * config_batch_size))\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        '''\n",
    "        if not step in included_batches:\n",
    "            #print(\"skip batch\", step)\n",
    "            skip_counter += 1\n",
    "            continue\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())            \n",
    "            # Report progress.\n",
    "            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
    "        '''\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "     \n",
    "        # Fwd the whole batch\n",
    "        model.eval()\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "        if config_per_sample: \n",
    "            loss = torch.nn.CrossEntropyLoss(reduction='none')(outputs.logits, batch['labels'])  # per example loss                    \n",
    "            # loss history of all samples... discarded or not ...\n",
    "            loss_history = np.concatenate((loss_history, loss.cpu().detach().numpy()))\n",
    "        \n",
    "            # backprop based on loss threshold \n",
    "            for idx, l in enumerate(loss):\n",
    "                if l >= loss_threshold:\n",
    "                    for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                        #staged_batch[k] = torch.cat(staged_batch[k], batch[k][idx])\n",
    "                        staged_batch[k].append(batch[k][idx])\n",
    "                else:\n",
    "                    skip_counter += 1 \n",
    "                       \n",
    "            #######################################\n",
    "            # adjust loss threshold ... moving avg\n",
    "            if len(loss_history) > config_n_window:\n",
    "                loss_threshold = np.average(loss_history[-config_n_window:])\n",
    "                loss_threshold_history.append((step * config_batch_size - skip_counter, loss_threshold))\n",
    "        \n",
    "            ''' # backprop based on loss ranking in the minibatch ... not working well\n",
    "            lst = []\n",
    "            for idx,l in enumerate(loss):\n",
    "                lst.append((l.item(),idx))\n",
    "            lst.sort(reverse=True)\n",
    "            for l,idx in lst[0:int(len(lst)*keep_frac)]:\n",
    "                for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                    staged_batch[k].append(batch[k][idx])\n",
    "            skip_counter += keep_frac\n",
    "            '''\n",
    "        \n",
    "            optimizer.zero_grad()   # just in case ...\n",
    "            \n",
    "            # less than 1 batch for backprop ... later\n",
    "            #n_batches = staged_batch['input_ids'].size(dim=0)\n",
    "            n_batches = len(staged_batch['input_ids'])        \n",
    "            # print(\"n_batches = \", n_batches)        \n",
    "            if n_batches < config_batch_size:\n",
    "                continue\n",
    "\n",
    "            # has a batch to backprop ... split a batch of 8\n",
    "            # https://pytorch.org/docs/stable/generated/torch.split.html            \n",
    "            #batch = {'input_ids':[], 'attention_mask':[], 'labels':[]}\n",
    "\n",
    "            for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                # if n_batches == config_batch_size:\n",
    "                #     batch[k] = torch.clone(staged_batch[k])\n",
    "                # else: \n",
    "                #     batch[k], staged_batch[k] = torch.split(staged_batch[k], config_batch_size)\n",
    "                #for b in staged_batch[k][0:config_batch_size]:\n",
    "\n",
    "                # if k == 'labels':  # build a 1-d tensor for a list of 0-d tensors. can't cat\n",
    "                #     batch[k] = torch.tensor(staged_batch[k][0:config_batch_size]).to(device)\n",
    "                # else: # build 2d tensor from a list of 1d tensors. can cat\n",
    "                #     batch[k] = torch.cat(staged_batch[k][0:config_batch_size]).to(device)  # already on device??\n",
    "\n",
    "                batch[k] = torch.stack(staged_batch[k][0:config_batch_size]).to(device)  # already on device??\n",
    "                staged_batch[k] = staged_batch[k][config_batch_size:]\n",
    "\n",
    "        else: # per minibatch \n",
    "            loss = outputs.loss\n",
    "            #loss_history.append(loss.cpu().detach().numpy())\n",
    "            # np.concatenate((loss_history, loss.cpu().detach().numpy()))\n",
    "            loss_history = np.append(loss_history, loss.item())\n",
    "            \n",
    "            #######################################\n",
    "            # adjust loss threshold ... moving avg\n",
    "            win = int(config_n_window / config_batch_size) \n",
    "            if len(loss_history) > win:\n",
    "                loss_threshold = np.average(loss_history[-config_n_window:])\n",
    "                loss_threshold_history.append((step * config_batch_size - skip_counter, loss_threshold))\n",
    "                        \n",
    "            if loss.item() < loss_threshold: \n",
    "                skip_counter += config_batch_size\n",
    "                optimizer.zero_grad()   # just in case ...\n",
    "                continue\n",
    "                                                                                 \n",
    "        model.train()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # loss is a tensor containing a single val\n",
    "        total_loss += loss.item()\n",
    "        #loss_history_eff.append((step, loss.item(), 1))   # 1 means backprop        \n",
    "        # loss history of samples for training ... i.e. not discarded ...\n",
    "        if config_per_sample:\n",
    "            per_sample_loss = torch.nn.CrossEntropyLoss(reduction='none')(outputs.logits, batch['labels'])  # per example loss\n",
    "            loss_history_eff = np.concatenate((loss_history_eff, per_sample_loss.cpu().detach().numpy()))\n",
    "        else: \n",
    "            loss_history_eff = np.append(loss_history_eff, loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)        \n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(config_batch_size)\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    #avg_train_loss = total_loss / len(train_dataloader)     \n",
    "    avg_train_loss = total_loss / (len(train_dataloader) - skip_counter / config_batch_size)   # xzl\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
    "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))    \n",
    "    print(f\"  skipped {skip_counter} samples, {100 * skip_counter/config_batch_size/len(train_dataloader):.2f}%\", \"loss_threshold\", loss_threshold)\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
    "    print(\"Accuracy: \", metric.compute())    \n",
    "    \n",
    "# print(loss_history)\n",
    "%matplotlib inline\n",
    "plt.hist(loss_history_eff, bins=40)\n",
    "plt.title(\"Effective Loss histo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80b768b2-ef71-4e02-8820-b507afafc1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Effective Loss vs # Sample\")\n",
    "plt.plot(loss_history_eff, 'ro', markersize=2)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Loss Threshold vs # Sample\")\n",
    "ts = np.transpose(loss_threshold_history)\n",
    "plt.scatter(ts[0],ts[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a29b6f-7112-46ca-98cc-05d2aad57574",
   "metadata": {},
   "source": [
    "# end of plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8a477-5857-4250-b20e-ea2af449b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(optimizer.state['grad_history'])\n",
    "\n",
    "# gradient ... low to high\n",
    "s = sorted(optimizer.state['grad_history'], key = lambda x: x[1])    \n",
    "# loss  ... low to high\n",
    "# s = sorted(loss_history, key = lambda x: x[1])    \n",
    "\n",
    "plt.hist(list(map(lambda x: x[1], optimizer.state['grad_history'])), bins=40)\n",
    "plt.title(\"Gradient histo\")\n",
    "\n",
    "#print(s)\n",
    "#print(s[int(9*len(s)/10):-1])  # top 10% \n",
    "#print(s[90:-1])\n",
    "bottom10 = s[0:int(1*len(s)/10)]\n",
    "bottom50 = s[0:int(5*len(s)/10)]\n",
    "bottom75 = s[0:int(7.5*len(s)/10)]\n",
    "bottom90 = s[0:int(9*len(s)/10)]\n",
    "\n",
    "top10 = s[int(9*len(s)/10):-1]\n",
    "top25 = s[int(7.5*len(s)/10):-1]\n",
    "\n",
    "#print(\"bot50\", bottom50)\n",
    "#print(\"bot50\", bottom50[-1])\n",
    "#print(\"top10\", top10)\n",
    "#print(\"top10\", top10[0])\n",
    "\n",
    "included_batches = [x[0] for x in bottom10] \n",
    "for x in included_batches:\n",
    "    print(x, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4952af6-9978-46c4-ac79-8688860cfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all epoches (no validation)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384d11c-028d-45c9-bd49-c0a259a3818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "#metric = load_metric(\"glue\", \"mrpc\")\n",
    "metric = load_metric(\"glue\", \"sst2\")  # same as accuracy\n",
    "# metric = load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}