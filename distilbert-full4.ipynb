{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc2a082-418b-4252-ac77-4fd04360ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "#!pip install datasets transformers[sentencepiece]\n",
    "#!pip install ipywidgets\n",
    "#!pip install torchsummary \n",
    "#!pip install accelerate \n",
    "#!pip3 install matplotlib\n",
    "\n",
    "# cf: Huggingface\n",
    "# https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb#scrollTo=nZ09SFwfjXNO\n",
    "# Google\n",
    "# https://colab.research.google.com/github/501Good/tartu-nlp-2020/blob/master/labs/lab6/Lab6_TransformersClassification.ipynb#scrollTo=yfUd-Wr3t7rO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812ab5e7-0a11-4244-8d32-e7351114ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "# xzl\n",
    "config_batch_size = 8\n",
    "config_per_sample = False   # otherwise per minibatch\n",
    "config_n_window = 100 # mov window avg for cal loss threshold, in num of samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a72bb884-d550-4348-9ffb-96a9139905fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pre-trained\n",
    "# #  ... many weights are not init'd... random??\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "# metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "068c3483-8562-4e7e-8134-96c5779a5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dump model \n",
    "#\n",
    "# cf: \n",
    "# https://stackoverflow.com/questions/68577198/pytorch-summary-fails-with-huggingface-model\n",
    "# https://stackoverflow.com/questions/68585678/pytorch-summary-fails-with-huggingface-model-ii-expected-all-tensors-to-be-on-t\n",
    "# torch info doc: \n",
    "# https://github.com/TylerYep/torchinfo\n",
    "# ... works, but not very helpful\n",
    "# summary(model,input_size=(8,512), dtypes=['torch.IntTensor'], device='cpu',verbose=1) \n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "#    if param.requires_grad:\n",
    "#        print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd25d66e-80eb-4d60-94ac-0c44af16e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################\n",
    "# # save model ...\n",
    "# ########################\n",
    "# # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "# output_dir = './model_save/'\n",
    "\n",
    "# # Create output directory if needed\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# # They can then be reloaded using `from_pretrained()`\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "# model_to_save.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# # Good practice: save your training arguments together with the trained model\n",
    "# # torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d7dbb89-e0e3-48bf-9b2c-c3cd55a37bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "\n",
    "output_dir = './distilbert/model_save/'  # VScode needs this relative path??\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "metric = load_metric(\"accuracy\")\n",
    "# Copy the model to the GPU.\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# freeze transformer layers (TODO: freeze other layers??)\n",
    "# for param in model.distilbert.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e72317-77d6-4415-8090-f57c568d44e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xzl: this???\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "def to_bin_class(ex):\n",
    "\tex['label'] = round(ex['label'])\n",
    "\treturn ex\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "\treturn tokenizer(ex['sentence'], padding='max_length', truncation=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\tlogits, labels = eval_pred\n",
    "\tpreds = np.argmax(logits, axis=-1)\n",
    "\treturn metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69abea0a-1876-4bb1-83e0-78fd7e36b0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sst (/u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e6d9d8d21a48058f350d78e5a83dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-175e01bd44ae6e77.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-bcfe3eb7a84204f3.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-d17996794240dda4.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-a4488ee52a49920a.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1c1de7b235a26b22.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-e13f66f58e1dc770.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-06d3078ae7eb71f3.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6a6653c780b8a2f8.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6156dac3d1bbf9dd.arrow\n"
     ]
    }
   ],
   "source": [
    "sst = load_dataset('sst', 'default')\n",
    "#sst = load_dataset('glue', 'sst2')\n",
    "sst = sst.remove_columns(['tokens', 'tree'])\n",
    "sst = sst.map(to_bin_class)\n",
    "sst = sst.cast_column('label', ClassLabel(num_classes=2))\n",
    "\n",
    "sst_tokenized = sst.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e98b7fda-569a-4e06-991a-52aa73dceb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "sst_tokenized = sst_tokenized.remove_columns(['sentence'])\n",
    "\n",
    "trn_set = sst_tokenized['train']\n",
    "num_trn = trn_set.num_rows\n",
    "trn_set_10 = torch.utils.data.Subset(trn_set, list(range(0,int(num_trn/10))))\n",
    "trn_set_50 = torch.utils.data.Subset(trn_set, list(range(0,int(num_trn/2))))\n",
    "tst_set = sst_tokenized['test']\n",
    "val_set = sst_tokenized['validation']\n",
    "\n",
    "print(val_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e4ecf5f-a1e0-4f51-8083-ab2eb37d68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20107918e48c4d08a35807cf76365f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a7fd750de98eccdc.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cb82f2b3146ed290.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc351fc2d3a49113.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ee0643d23beb47af.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-44f2a071873c044a.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-83c969729e91a5a4.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-87c8a936d9806164.arrow\n",
      "Loading cached processed dataset at /u/xl6yq/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0877df3f27e3fb69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8a54d16ae24aae939580178d507062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sst2 = load_dataset('glue', 'sst2')\n",
    "sst2 = sst2.map(to_bin_class)\n",
    "sst2 = sst2.cast_column('label', ClassLabel(num_classes=2))\n",
    "\n",
    "sst2_tokenized = sst2.map(tokenize_fn, batched=True)\n",
    "\n",
    "sst2_tokenized = sst2_tokenized.remove_columns(['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc23bd52-8344-480b-b8d5-98c7b8baae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "trn_set = sst_tokenized['train']\n",
    "num_trn = trn_set.num_rows\n",
    "tst_set = sst_tokenized['test']\n",
    "val_set = sst_tokenized['validation']\n",
    "\n",
    "print(val_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51370166-f49a-4af6-a17d-5e5f34e8017e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data loader, split into train/eval sets\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "   trn_set, shuffle=True, batch_size=config_batch_size, collate_fn=data_collator\n",
    "   # trn_set_100, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator\n",
    "    # trn_set_500, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator    \n",
    "    # trn_set_1000, shuffle=False, batch_size=config_batch_size, collate_fn=data_collator    \n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    val_set, batch_size=config_batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4db319f2-fadd-4e4f-afec-09f04a431300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 512]),\n",
       " 'attention_mask': torch.Size([8, 512]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a batch is a dict. k is col name, e.g. 'input_ids'. v is a 2D tensor (8x512 in our case)\n",
    "\n",
    "# sanity check data ...\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}    \n",
    "#batch.items()\n",
    "#print(batch['input_ids'])\n",
    "#print(\"train #batches=\",len(train_dataloader))\n",
    "#print(\"val #batches=\",len(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9902d696-e69b-4d32-94b7-8b6339f35a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6738, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n",
      "SequenceClassifierOutput(loss=tensor(0.6738, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0797,  0.0803],\n",
      "        [-0.0602,  0.0650],\n",
      "        [-0.0744,  0.0644],\n",
      "        [-0.0747,  0.0672],\n",
      "        [-0.0431,  0.0467],\n",
      "        [-0.0899,  0.0643],\n",
      "        [-0.1066,  0.0938],\n",
      "        [-0.0630,  0.0500]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "tensor([[0.4601, 0.5399],\n",
      "        [0.4688, 0.5312],\n",
      "        [0.4654, 0.5346],\n",
      "        [0.4646, 0.5354],\n",
      "        [0.4776, 0.5224],\n",
      "        [0.4615, 0.5385],\n",
      "        [0.4501, 0.5499],\n",
      "        [0.4718, 0.5282]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run one batch\n",
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)\n",
    "print(outputs)\n",
    "# probablity\n",
    "print(torch.nn.functional.softmax((outputs.logits),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d58a1b57-066d-426b-9ab8-a9af38583e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor t in optimizer.param_groups[0]['params']:\\n    print(t.shape)\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... prep optim lr scheduler etc  ... \n",
    "#from transformers import AdamW    # deprecated\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# optimizer.param_groups[0]['params']\n",
    "# print(len(optimizer.param_groups[0]['params']))\n",
    "\n",
    "'''\n",
    "for t in optimizer.param_groups[0]['params']:\n",
    "    print(t.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c11fc988-40fa-4023-935f-15dffa473546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 2    # xzl. default:3\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "# print(model)  # can be useful\n",
    "\n",
    "#summary(model,input_size=(8,512)) # ... type errors??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d540a53-4987-4307-bfd1-29f763cf0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "# excluded_batches = []\n",
    "# bottom 50%\n",
    "# excluded_batches = [0,2,6,5,1,4,3,8,7,10,9,11,581,870,525,785,12,13,827,811,422,973,1021,14,320,967,140,122,583,624,935,542,936,924,618,777,22,591,888,331,32,593,852,813,297,825,15,156,687,30,75,1029,643,538,774,19,530,234,287,25,724,943,316,93,978,427,384,611,464,750,900,361,432,519,208,760,553,625,336,982,111,179,312,104,471,26,845,17,68,855,695,139,293,177,552,144,897,548,706,1036,856,379,482,902,627,500,817,814,415,601,18,726,557,20,860,100,229,249,332,103,355,948,939,1049,824,579,822,895,450,1027,896,467,80,456,266,202,736,887,260,185,1062,974,1028,1060,781,933,165,309,255,480,240,700,108,232,461,993,184,381,458,296,1022,88,1001,395,323,91,1000,69,991,330,359,965,727,63,851,347,253,995,916,697,917,584,152,690,616,957,463,1006,843,76,466,378,135,663,286,50,770,410,539,201,92,879,506,647,70,236,245,998,181,248,404,741,29,954,209,306,246,119,268,949,133,1026,1056,418,449,196,682,221,918,863,806,1019,992,65,125,24,821,66,692,56,739,243,617,554,1015,397,550,416,79,748,95,406,409,149,1017,89,281,174,512,367,469,445,696,251,648,753,944,121,694,702,54,592,575,675,926,990,264,284,205,150,123,963,167,180,898,613,755,794,16,118,448,36,884,176,681,674,454,913,72,844,84,128,776,485,130,861,452,385,164,772,529,834,319,838,789,227,883,1011,468,988,479,672,274,803,407,1058,722,265,77,701,254,258,388,346,622,31,460,572,1033,413,698,484,38,612,1013,805,473,890,962,751,573,1047,637,462,389,956,113,951,927,375,937,282,82,197,244,971,168,98,33,964,368,382,451,1010,64,55,163,365,1031,537,1039,829,328,1025,603,833,641,324,711,880,486,459,1065,629,650,470,373,420,457,653,220,472,147,666,83,533,223,496,656,160,439,1023,947,1018,742,294,713,508,878,858,301,910,735,975,871,498,795,175,731,200,109,350,693,628,1024,28,157,342,730,551,646,1012,351,516,819,279,638,433,901,532,831,792,396,689,455,985,21,931,363,968,972,57,137,941,411,453,699,154,477,414,986,345,81,492,143,73,679,474,1009,206,425,952,145,1067,210,124,981,364,830,652,290,169,872,676,358,798,1005,899,773,906,636,678,325,869,172,400,252,846,441,745,570,1037,510,131,1064,737,606,644,231,360,1061,215,534,170,178,857,1032,408,994,812,1007,651,784,356,]\n",
    "# bottom 75%\n",
    "# excluded_batches = [16,4,12,18,6,7,22,13,9,19,11,5,2,14,17,20,25,21,15,3,10,27,24,8,1,29,23,30,28,26,0,32,31,670,34,630,943,168,979,225,33,92,940,599,595,989,456,1064,930,131,106,432,35,695,916,726,592,1014,453,729,565,622,117,806,637,258,1061,36,672,783,846,750,908,794,490,312,378,484,1047,814,144,980,854,947,145,404,318,566,781,498,506,1013,971,874,159,613,83,692,681,689,118,699,259,289,183,77,1002,128,60,415,417,160,1018,151,130,910,583,1043,679,684,139,1017,43,1010,757,1006,765,52,157,995,928,277,460,402,718,913,500,147,122,898,996,61,970,288,135,133,124,962,522,994,655,40,441,37,81,576,349,245,138,134,467,1031,38,50,529,774,961,333,914,45,915,963,905,74,152,964,430,362,330,201,331,395,337,1001,79,984,525,357,303,323,901,374,297,80,585,638,226,548,344,615,266,835,591,517,62,938,355,360,519,274,140,602,890,184,353,804,667,559,717,701,586,683,429,46,265,189,568,69,324,364,923,1036,499,472,937,827,521,82,85,343,687,282,438,792,745,222,72,112,580,171,464,927,291,121,120,268,569,75,925,627,501,748,546,55,785,1027,166,639,992,893,494,551,71,238,485,713,818,39,444,839,41,359,326,363,563,70,1011,953,823,990,673,325,859,78,746,843,656,960,669,577,1042,316,101,919,273,252,126,396,153,346,508,883,663,177,575,668,845,798,696,856,84,716,286,997,132,405,371,777,561,345,180,398,653,311,877,579,719,214,423,918,67,205,53,113,116,832,369,208,191,966,791,452,768,356,632,676,751,269,448,424,541,123,816,1055,550,873,865,380,372,657,926,543,704,86,851,1040,457,641,974,564,137,281,942,694,707,150,219,270,256,413,658,470,891,427,1065,944,648,742,428,262,852,284,903,597,520,414,193,198,838,691,301,626,549,959,710,909,253,954,310,581,574,382,786,491,711,473,685,836,931,620,154,584,329,878,65,876,848,59,475,822,706,42,820,682,93,828,801,367,322,451,882,635,279,594,532,582,573,217,264,216,867,866,129,978,1041,693,304,870,934,476,437,879,283,255,612,1054,624,233,513,739,425,643,320,1046,795,531,54,88,110,342,347,759,702,540,784,552,468,678,336,148,948,474,1039,246,642,976,399,1050,528,410,351,335,842,275,250,847,922,523,1032,1025,956,115,659,1058,334,76,190,267,108,778,315,932,125,486,888,352,516,988,633,397,578,478,221,1052,800,524,629,570,744,287,588,951,872,408,730,477,981,993,158,892,858,375,810,299,769,447,459,697,767,298,728,731,849,857,841,601,686,544,790,675,203,1004,1016,366,542,328,714,646,920,703,507,143,605,621,212,1020,412,753,977,911,936,808,454,889,338,982,518,896,560,272,443,276,509,57,824,895,593,502,1044,493,327,952,1051,875,625,688,645,63,793,787,73,619,1021,611,881,211,512,321,674,392,618,897,871,278,271,945,819,975,377,571,407,481,1045,662,724,169,426,968,339,572,194,370,439,230,514,261,463,983,383,368,782,607,972,213,306,254,234,690,812,533,1059,434,955,887,526,244,156,406,985,912,465,48,864,141,341,361,698,302,290,803,249,965,598,294,207,829,805,869,700,431,422,680,204,305,884,178,44,241,416,1009,243,192,537,248,202,98,837,538,365,215,536,181,1037,285,752,487,868,661,715,1003,175,182,530,164,247,419,185,949,223,172,732,562,723,503,917,1057,142,236,280,296,587,721,821,505,545,608,1030,780,735,87,206,969,497,558,567,504,96,308,257,89,99,510,1053,97,95,834,797,736,483,492,855,939,830,802,924,666,471,705,167,603,853,]\n",
    "\n",
    "# -- include all --- #\n",
    "included_batches = list(range(0, len(train_dataloader)))\n",
    "\n",
    "# loss, top 10 \n",
    "# included_batches = [0,12,606,28,908,14,629,647,229,961,683,156,921,84,868,74,1031,801,7,296,948,219,525,343,624,29,466,56,203,55,436,260,643,266,11,153,112,636,308,664,781,927,106,1024,465,197,726,19,278,90,173,50,533,53,42,925,357,77,902,612,281,318,799,43,911,263,422,111,259,198,71,225,482,832,723,782,790,588,476,689,904,383,479,631,139,556,771,1061,253,51,719,728,941,392,344,395,783,456,538,655,973,968,282,83,965,756,]\n",
    "# bottom 10\n",
    "# included_batches = [593,1029,414,1009,574,529,417,678,966,398,843,616,594,869,597,651,998,1059,1051,338,402,899,875,931,883,129,1034,166,496,422,1013,695,781,412,485,1044,440,708,240,792,773,935,785,816,905,689,624,321,364,249,383,775,863,854,937,757,667,587,558,945,310,745,445,435,599,648,968,735,600,965,1060,893,924,1043,231,81,888,592,608,1019,404,256,575,856,679,956,581,641,343,583,643,507,582,699,761,842,436,397,1052,1066,248,330,782,783,395,391,]\n",
    "\n",
    "skip_counter = 0  # how many sample skipped\n",
    "\n",
    "#loss_history = []\n",
    "loss_history = np.array([], dtype=np.float32)\n",
    "loss_history_eff = np.array([], dtype=np.float32)   # effective. actual loss in training\n",
    "\n",
    "# loss_threshold = 0 # 0.4 # 0.4   # higher -> skip more; lower -> skip less\n",
    "loss_threshold = 0\n",
    "loss_threshold_history = []\n",
    "\n",
    "#for picking examples based on rankings in a minibatch. only backprop these examples\n",
    "keep_frac = 0.5   \n",
    "\n",
    "# dict()\n",
    "# list of 1D tensors...\n",
    "staged_batch = {'input_ids':[], 'attention_mask':[], 'labels':[]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165d98de-5345-4cc6-81c1-19471a49d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74cd1b4f27540ce84443e1645c828c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=110'>111</a>\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m# per minibatch \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=111'>112</a>\u001b[0m     loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=112'>113</a>\u001b[0m     loss_history\u001b[39m.\u001b[39;49mappend(loss\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())  \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=114'>115</a>\u001b[0m     \u001b[39m#######################################\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=115'>116</a>\u001b[0m     \u001b[39m# adjust loss threshold ... moving avg\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv15/u/xl6yq/workspace-transformer/distilbert/distilbert-full4.ipynb#ch0000017vscode-remote?line=116'>117</a>\u001b[0m     win \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(config_n_window \u001b[39m/\u001b[39m config_batch_size) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# train/validation per epoch\n",
    "loss_values = []\n",
    "\n",
    "loss_threshold_history.append((0, loss_threshold))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, num_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    skip_counter = 0\n",
    "    \n",
    "    progress_bar = tqdm(range(len(train_dataloader)))\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        '''\n",
    "        if not step in included_batches:\n",
    "            #print(\"skip batch\", step)\n",
    "            skip_counter += 1\n",
    "            continue\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())            \n",
    "            # Report progress.\n",
    "            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
    "        '''\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "     \n",
    "        # Fwd the whole batch\n",
    "        model.eval()\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "        if config_per_sample: \n",
    "            loss = torch.nn.CrossEntropyLoss(reduction='none')(outputs.logits, batch['labels'])  # per example loss                    \n",
    "            # loss history of all samples... discarded or not ...\n",
    "            loss_history = np.concatenate((loss_history, loss.cpu().detach().numpy()))\n",
    "        \n",
    "            # backprop based on loss threshold \n",
    "            for idx, l in enumerate(loss):\n",
    "                if l >= loss_threshold:\n",
    "                    for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                        #staged_batch[k] = torch.cat(staged_batch[k], batch[k][idx])\n",
    "                        staged_batch[k].append(batch[k][idx])\n",
    "                else:\n",
    "                    skip_counter += 1 \n",
    "                       \n",
    "            #######################################\n",
    "            # adjust loss threshold ... moving avg\n",
    "            if len(loss_history) > config_n_window:\n",
    "                loss_threshold = np.average(loss_history[-config_n_window:])\n",
    "                loss_threshold_history.append((step * config_batch_size - skip_counter, loss_threshold))\n",
    "        \n",
    "            ''' # backprop based on loss ranking in the minibatch ... not working well\n",
    "            lst = []\n",
    "            for idx,l in enumerate(loss):\n",
    "                lst.append((l.item(),idx))\n",
    "            lst.sort(reverse=True)\n",
    "            for l,idx in lst[0:int(len(lst)*keep_frac)]:\n",
    "                for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                    staged_batch[k].append(batch[k][idx])\n",
    "            skip_counter += keep_frac\n",
    "            '''\n",
    "        \n",
    "            optimizer.zero_grad()   # just in case ...\n",
    "            \n",
    "            # less than 1 batch for backprop ... later\n",
    "            #n_batches = staged_batch['input_ids'].size(dim=0)\n",
    "            n_batches = len(staged_batch['input_ids'])        \n",
    "            # print(\"n_batches = \", n_batches)        \n",
    "            if n_batches < config_batch_size:\n",
    "                continue\n",
    "\n",
    "            # has a batch to backprop ... split a batch of 8\n",
    "            # https://pytorch.org/docs/stable/generated/torch.split.html            \n",
    "            #batch = {'input_ids':[], 'attention_mask':[], 'labels':[]}\n",
    "\n",
    "            for k in ['input_ids', 'attention_mask', 'labels']:\n",
    "                # if n_batches == config_batch_size:\n",
    "                #     batch[k] = torch.clone(staged_batch[k])\n",
    "                # else: \n",
    "                #     batch[k], staged_batch[k] = torch.split(staged_batch[k], config_batch_size)\n",
    "                #for b in staged_batch[k][0:config_batch_size]:\n",
    "\n",
    "                # if k == 'labels':  # build a 1-d tensor for a list of 0-d tensors. can't cat\n",
    "                #     batch[k] = torch.tensor(staged_batch[k][0:config_batch_size]).to(device)\n",
    "                # else: # build 2d tensor from a list of 1d tensors. can cat\n",
    "                #     batch[k] = torch.cat(staged_batch[k][0:config_batch_size]).to(device)  # already on device??\n",
    "\n",
    "                batch[k] = torch.stack(staged_batch[k][0:config_batch_size]).to(device)  # already on device??\n",
    "                staged_batch[k] = staged_batch[k][config_batch_size:]\n",
    "\n",
    "        else: # per minibatch \n",
    "            loss = outputs.loss\n",
    "            #loss_history.append(loss.cpu().detach().numpy())\n",
    "            np.concatenate((loss_history, loss.cpu().detach().numpy()))\n",
    "            \n",
    "            #######################################\n",
    "            # adjust loss threshold ... moving avg\n",
    "            win = int(config_n_window / config_batch_size) \n",
    "            if len(loss_history) > win:\n",
    "                loss_threshold = np.average(loss_history[-config_n_window:])\n",
    "                loss_threshold_history.append((step * config_batch_size - skip_counter, loss_threshold))\n",
    "                        \n",
    "            if loss.item() < loss_threshold: \n",
    "                skip_counter += config_batch_size\n",
    "                optimizer.zero_grad()   # just in case ...\n",
    "                continue\n",
    "                                                         \n",
    "        model.train()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # loss is a tensor containing a single val\n",
    "        total_loss += loss.item()\n",
    "        #loss_history_eff.append((step, loss.item(), 1))   # 1 means backprop        \n",
    "        # loss history of samples for training ... i.e. not discarded ...\n",
    "        if config_per_sample:\n",
    "            per_sample_loss = torch.nn.CrossEntropyLoss(reduction='none')(outputs.logits, batch['labels'])  # per example loss\n",
    "            loss_history_eff = np.concatenate((loss_history_eff, per_sample_loss.cpu().detach().numpy()))\n",
    "        else: \n",
    "            loss_history_eff = np.concatenate(loss_history_eff, loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)        \n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    #avg_train_loss = total_loss / len(train_dataloader)     \n",
    "    avg_train_loss = total_loss / (len(train_dataloader) - skip_counter / config_batch_size)   # xzl\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
    "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))    \n",
    "    print(f\"  skipped {skip_counter} samples, {100 * skip_counter/config_batch_size/len(train_dataloader):.2f}%\", \"loss_threshold\", loss_threshold)\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
    "    print(\"Accuracy: \", metric.compute())    \n",
    "    \n",
    "# print(loss_history)\n",
    "%matplotlib inline\n",
    "plt.hist(loss_history_eff, bins=40)\n",
    "plt.title(\"Effective Loss histo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b768b2-ef71-4e02-8820-b507afafc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Effective Loss vs # Sample\")\n",
    "plt.plot(loss_history_eff, 'ro', markersize=2)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Loss Threshold vs # Sample\")\n",
    "ts = np.transpose(loss_threshold_history)\n",
    "plt.scatter(ts[0],ts[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42ea7c-1556-45e1-ad6f-14690989bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(optimizer.state['grad_history'])\n",
    "\n",
    "# gradient ... low to high\n",
    "s = sorted(optimizer.state['grad_history'], key = lambda x: x[1])    \n",
    "# loss  ... low to high\n",
    "# s = sorted(loss_history, key = lambda x: x[1])    \n",
    "\n",
    "plt.hist(list(map(lambda x: x[1], optimizer.state['grad_history'])), bins=40)\n",
    "plt.title(\"Gradient histo\")\n",
    "\n",
    "#print(s)\n",
    "#print(s[int(9*len(s)/10):-1])  # top 10% \n",
    "#print(s[90:-1])\n",
    "bottom10 = s[0:int(1*len(s)/10)]\n",
    "bottom50 = s[0:int(5*len(s)/10)]\n",
    "bottom75 = s[0:int(7.5*len(s)/10)]\n",
    "bottom90 = s[0:int(9*len(s)/10)]\n",
    "\n",
    "top10 = s[int(9*len(s)/10):-1]\n",
    "top25 = s[int(7.5*len(s)/10):-1]\n",
    "\n",
    "#print(\"bot50\", bottom50)\n",
    "#print(\"bot50\", bottom50[-1])\n",
    "#print(\"top10\", top10)\n",
    "#print(\"top10\", top10[0])\n",
    "\n",
    "included_batches = [x[0] for x in bottom10] \n",
    "for x in included_batches:\n",
    "    print(x, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4952af6-9978-46c4-ac79-8688860cfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all epoches (no validation)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384d11c-028d-45c9-bd49-c0a259a3818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "#metric = load_metric(\"glue\", \"mrpc\")\n",
    "metric = load_metric(\"glue\", \"sst2\")  # same as accuracy\n",
    "# metric = load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99a4a8-bc10-4069-8d51-049fef7d55fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
